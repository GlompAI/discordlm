# Discord Bot Configuration
BOT_TOKEN=your_discord_bot_token_here

# LLM Configuration
# LLM Provider: gemini, openai, or ollama
LLM_PROVIDER=gemini

# Gemini (if provider is gemini)
# GEMINI_API_KEY=your_gemini_api_key_here
# GEMINI_BASE_URL=
# GEMINI_TOKEN_LIMIT=1000000
# GEMINI_MODEL_NAME=gemini-2.5-flash

# OpenAI (if provider is openai)
# OPENAI_API_KEY=
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_VISION_SUPPORT=false
# OPENAI_CUSTOM_HEADER_KEY=x-api-key
# OPENAI_TOKEN_LIMIT=32000

# Ollama (if provider is ollama)
# OLLAMA_HOST=http://localhost:11434

# Optional: Number of parallel inference requests to allow
# INFERENCE_PARALLELISM=1

# Optional: Rate limit per user (requests per minute)
# Default: 10 requests per minute
# RATE_LIMIT_PER_MINUTE=10

# Optional: User ID to bypass administrator checks
# ADMIN_OVERRIDE_ID=your_user_id_here

# Optional: Maximum number of messages to fetch for history
# Default: 200
# MAX_HISTORY_MESSAGES=200

# Optional: Enable debug logging
# DEBUG=true

# Groq support
# GROQ_API_KEY=
# GROQ_MODEL_NAME=llama3-8b-8192
